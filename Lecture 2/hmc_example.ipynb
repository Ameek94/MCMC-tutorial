{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from scipy.stats import norm, multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the HMC for the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with the Banana likelihood in [-1,2]^2\n",
    "\n",
    "def loglike(X):\n",
    "    logpdf = -0.25*(5*(0.2-X[0]))**2 - (20*(X[1]/4 - X[0]**4))**2\n",
    "    return logpdf\n",
    "\n",
    "def grad_loglike(X):\n",
    "    gradx = 12.5*(0.2 - X[0]) + 3200*X[0]**3 *(-X[0]**4 + X[1]/4)\n",
    "    grady = -200*(-X[0]**4 + X[1]/4)\n",
    "    return np.array([gradx,grady])\n",
    "\n",
    "def HMC(x0,num_samples,num_steps=30,step_size=0.01):\n",
    "\n",
    "    p_dist = multivariate_normal(mean=[0,0],cov=np.eye(2)) # use to draw new momenta and compute kinetic energy\n",
    "    samples = []\n",
    "    samples.append(x0)\n",
    "\n",
    "    for i in range(0,num_samples):\n",
    "        # draw random momentum\n",
    "\n",
    "        # evolve from current state to new state using H\n",
    "\n",
    "        # compute transition probability\n",
    "\n",
    "        # print(H_state,H_new)\n",
    "\n",
    "        # do transition\n",
    "        if (a > np.random.uniform(0,1)):\n",
    "            x_state = x_new\n",
    "        samples.append(x_state)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def evolve(x,p,num_steps,step_size):\n",
    "    # evolve the Hamiltonian for num_steps with step_size using the leapfrog integrator\n",
    "    # this is good at conserving energy so numerical error is lower, which means a high acceptance rate :)\n",
    "    # x, p = x[:], p[:]\n",
    "    for i in range(num_steps):\n",
    "        p = p - (step_size / 2) * grad_loglike(x)\n",
    "        x = x + step_size * p\n",
    "        p = p - (step_size / 2) * grad_loglike(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "# x0 choice below is to ensure good starting point\n",
    "samples = HMC(0.02+0.01*np.random.randn(2),num_samples=10000,num_steps=25,step_size=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot function vs your samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1, 500)\n",
    "y = np.linspace(-1,2, 500)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "grid = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "\n",
    "def loglike(X):\n",
    "    logpdf = -0.25*(5*(0.2-X[:,0]))**2 - (20*(X[:,1]/4 - X[:,0]**4))**2\n",
    "    # print(logpdf)\n",
    "    return logpdf\n",
    "\n",
    "func = np.exp(loglike(grid).reshape(x.shape[0],y.shape[0]))\n",
    "\n",
    "print(func.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize= (12,4))\n",
    "\n",
    "for axes in ax:\n",
    "    cont = axes.contourf(x,y,func,cmap='Blues_r')\n",
    "    fig.colorbar(cont,ax=axes)\n",
    "\n",
    "ax[1].scatter(samples[:,0],samples[:,1],alpha=0.1,s=4,color='C1')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
